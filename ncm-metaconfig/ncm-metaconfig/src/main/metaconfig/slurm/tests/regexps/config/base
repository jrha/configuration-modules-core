Config file for main slurm daemon
---
/etc/slurm/slurm.conf
quote
---

# accounting

AccountingStorageEnforce=qos,safe
AccountingStorageHost=slurmdb.example.org
AccountingStorageType=accounting_storage/slurmdbd
AccountingStoreFlags=job_comment,job_env
JobAcctGatherFrequency=energy=10,network=30
JobAcctGatherType=jobacct_gather/cgroup
JobCompLoc=/var/spool/slurm/job_completions.log
JobCompType=jobcomp/filetxt

# control

AuthAltParameters=jwt_key=/etc/slurm/jwt.key
AuthAltTypes=auth/jwt
AuthType=auth/munge
ClusterName=thecluster
CommunicationParameters=block_null_hash
ControlMachine=master.example.com
CryptoType=crypto/munge
DisableRootJobs=YES
EnforcePartLimits=NO
FirstJobId=1
GresTypes=gpu,mps
GroupUpdateForce=NO
GroupUpdateTime=600
JobContainerType=job_container/tmpfs
JobSubmitPlugins=lua,pbs
LaunchParameters=use_interactive_step
MailProg=/bin/mail
MaxJobCount=5000
MaxJobId=9999999
MaxStepCount=40000
MaxTasksPerNode=128
MinJobAge=300
MpiDefault=none
PrivateData=jobs,accounts,nodes,reservations,usage
ProctrackType=proctrack/cgroup
ReturnToService=1
ScronParameters=enable

# logging

SlurmctldDebug=debug3
SlurmctldLogFile=/var/log/slurmctld
SlurmdDebug=debug4
SlurmdLogFile=/var/log/slurmd

# nodes

NodeName=DEFAULT CPUs=4 CoresPerSocket=1 RealMemory=3500 Sockets=4 State=UNKNOWN ThreadsPerCore=1
NodeName=node1,node2 CPUs=8 CoresPerSocket=1 Gres=gpu:kepler1:1,gpu:tesla1:1,bandwidth:lustre:no_consume:4194304 RealMemory=3500 Sockets=4 State=UNKNOWN ThreadsPerCore=2

DownNodes=DEFAULT State=FAIL
DownNodes=node8,node9 Reason="in progress" State=FAILING

FrontendName=DEFAULT AllowUsers=usera,userb State=UNKNOWN
FrontendName=login1,login2 Reason="in progress" State=FAILING


# partitions

PartitionName=abc Default=YES DisableRootJobs=YES MaxTime=4320 Nodes=ALL State=UP
PartitionName=thepartition-debug DisableRootJobs=NO MaxTime=4320 Nodes=node2801,node2802 State=DOWN

# priority

PriorityCalcPeriod=5
PriorityDecayHalfLife=10080
PriorityFavorSmall=NO
PriorityFlags=FAIR_TREE
PriorityMaxAge=40320
PriorityType=priority/multifactor
PriorityWeightAge=5000
PriorityWeightFairshare=7000
PriorityWeightJobSize=2500

# process

SlurmUser=slurm
SlurmctldParameters=max_dbd_msg_action=discard,power_save_interval=20
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurm/slurmd
StateSaveLocation=/var/spool/slurm
SwitchType=switch/none
TaskPlugin=task/affinity,task/cgroup

# scheduling

DefCpuPerGPU=3
DefMemPerCPU=123
DependencyParameters=max_depend_depth=5
FastSchedule=1
MaxMemPerNode=345
SchedulerParameters=batch_sched_delay=5,bf_continue,bf_max_job_test=1024,bf_window=4320,default_queue_depth=128,partition_job_depth=5
SchedulerType=sched/backfill
SelectType=select/cons_res
SelectTypeParameters=CR_Core_Memory

# timers

InactiveLimit=0
KillWait=30
SlurmctldTimeout=120
SlurmdTimeout=300
WaitTime=0

